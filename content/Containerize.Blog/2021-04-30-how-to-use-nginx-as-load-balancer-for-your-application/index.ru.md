---
title: "Как использовать Nginx в качестве балансировщика нагрузки для вашего приложения" 
seoTitle: "Как использовать Nginx в качестве балансировщика нагрузки для вашего приложения" 
description: "Nginx-это популярный веб-сервер с открытым исходным кодом. Это хорошо известно высокой производительности и масштабируемостью. В этом уроке мы научимся использовать Nginx в качестве балансировщика нагрузки" 
date: Fri, 30 Apr 2021 07:31:14 +0000
author: Assad Mahmood
summary: "Nginx популярен благодаря высокой производительности и масштабируемости. Это веб -сервер с открытым исходным кодом. В этом уроке мы научимся использовать Nginx в качестве балансировщика нагрузки." 
url: /ru/how-to-use-nginx-as-load-balancer-for-your-application/
categories: ['Web Server Solution Stack']
---

## Nginx популярен благодаря высокой производительности и масштабируемости. Это веб -сервер с открытым исходным кодом. В этом уроке мы научимся использовать Nginx в качестве балансировщика нагрузки.

{{< figure align=center src="images/nginx-as-load-balancer.png" alt="Как использовать nginx в качестве балансировщика нагрузки">}}

Современные веб -сайты с высоким трафиком обслуживают сотни тысяч, а в некоторых случаях миллионы одновременных запросов от пользователей или клиентов и возвращают правильный текст, изображения, видео или данные приложения, - все это быстро и надежно. Для удовлетворения потребностей этих высоких объемов и вычислительной мощности вам нужно больше серверов. С большим количеством серверов вам нужен способ загрузить баланс трафика между этими серверами. В этом учебном пособии блога мы рассмотрим, что такое балансировщик нагрузки и как мы можем использовать Nginx в качестве балансировщика нагрузки.
Чтобы настроить балансировку нагрузки NGINX в качестве обязательного условия, вам нужно будет иметь как минимум два хоста с установленным и настроенным программным обеспечением веб -сервера, чтобы увидеть преимущества нагрузки, балансируя Nginx. Если у вас уже есть один запущенный веб -хост, настройка, продублируйте его, создав пользовательское изображение и разверните его на новом веб -сервере. Итак, давайте узнаем, как настроить Nginx Balancing Balancing Configuration Configuration, шаг за шагом для ваших облачных серверов.!
* **[Nginx Web Server][1]** 
* **[балансировщик нагрузки][2]** 
* **[Настройка nginx как балансировщик нагрузки (круглый робин)][3]** 
* **[о разных направлениях вверх по течению][4]** 
* **[Заключение][5]** 

## Nginx Web Server {#webserver}

Nginx-это высокопроизводительный веб-сервер с открытым исходным кодом. В дополнение к своим возможностям HTTP Server, Nginx также может функционировать как прокси -сервер для электронной почты (IMAP, POP3 и SMTP) и обратный прокси и загружать баланс Nginx для серверов HTTP, TCP и UDP. Это повышает производительность, надежность и безопасность ваших приложений. Он популярен благодаря своим богатым набором функций, простой конфигурации и низким потреблением ресурсов.
Как работает Nginx? NGINX обычно используется в качестве балансировщика обратной прокси -нагрузки NGINX в качестве единой точки входа в распределенное веб -приложение, работающее на нескольких отдельных серверах. Он использует асинхронный подход, управляемый событиями, чтобы предложить низкое использование памяти и высокую параллелию. Вы можете прочитать больше о Nginx [здесь][6].

## Балансировщик нагрузки {#loadbalancer}

Балансировка нагрузки - это процесс распространения сетевого трафика по нескольким серверам. И «программное обеспечение» или «оборудование», которое выполняет этот процесс распространения, называется балансировщиком нагрузки. Балансировщик нагрузки похож на «дорожного полицейского», стоящего перед вашим сервером и маршрутизации запросов клиентов на всех серверах. Он гарантирует, что ваше приложение остается эксплуатационным, даже если один из серверов уходит.

{{< figure align=center src="images/223F67DC-2518-4CDD-883A-7DAF3C78A7CC.png" alt="nginx как балансировщик нагрузки">}}

Основные функции балансировщика нагрузки следующие:
  * Эффективно распределяет запросы клиента или сетевую загрузку на несколько серверов
  * Обеспечивает высокую доступность и надежность, отправляя запросы только на серверы, которые онлайн
  * Обеспечивает гибкость для добавления или вычтения серверов, поскольку спрос диктует

## Настройка nginx как балансировщик нагрузки {#setup}

Перед настройкой балансировки нагрузки Nginx Roubin вы должны установить Nginx на вашем сервере. Вы можете установить его быстро с помощью apt-get:
```
sudo apt-get install nginx
```
Чтобы настроить балансировщик нагрузки с круглой робином, нам нужно будет использовать модуль NGINX вверх по течению. Мы обновим конфигурацию балансировщика нагрузки NGINX в настройки NGINX. Давайте откроем конфигурацию вашего сайта. Для этого примера я использую файл конфигурации по умолчанию
```
sudo vi /etc/nginx/sites-available/default
```
Нам нужно добавить конфигурацию балансировки нагрузки в файл для настройки балансировщика нагрузки с помощью Nginx.
Сначала нам нужно включить модуль вверх по течению для балансировки нагрузки NGINX, который выглядит так:
```
upstream backend  {
  server backend1.example.com;
  server backend2.example.com;
  server backend3.example.com;
}
```
Используйте этот бэкэнд вверх по течению в качестве конечной точки прокси в блоке вашего сервера:
```
server {
  location / {
    proxy_pass  http://backend;
  }
}
```
Перезапустить Nginx
```
sudo service nginx restart
```
Пока у вас есть все серверы, вы теперь должны обнаружить, что балансировщик нагрузки с открытым исходным кодом NGINX начнет распределять посетителей на серверы одинаково. Это равное распределение называется балансировкой нагрузки с круглой робином.

## Вверх по течению директивы {#upstream}

В нашем последнем примере мы использовали простой модуль вверх по течению для балансировки нагрузки с круглой робином, чтобы распределить трафик одинаково среди серверов. Тем не менее, есть много причин, по которым это может быть не самый эффективный способ работать с трафиком. Есть несколько директив, которые мы можем использовать для более эффективного направления посетителей сайта.

### Масса
Один из способов начать распределять пользователей на серверы с большей точностью - это выделить определенный вес на определенные машины. Nginx позволяет нам назначить число, указав пропорцию трафика, который должен быть направлен на каждый сервер.
Сбалансированная нагрузка, которая включала вес сервера, может выглядеть так:
```
upstream backend  {
  server backend1.example.com weight=1;
  server backend2.example.com weight=2;
  server backend3.example.com weight=4;
}
```
Вес по умолчанию составляет 1. с весом 2, Backend2.example будет отправлен вдвое больше трафика, чем Backend1, а Backend3 с весом 4 будет иметь дело с большим трафиком, чем Backend2 и в четыре раза больше, чем Backend 1

### Хэш
IP Hash позволяет серверам отвечать на клиентов в соответствии с их IP -адресом, отправляя посетителей обратно на один и тот же VPS каждый раз, когда они посещают (если этот сервер не работает). Если сервер, как известно, неактивен, он должен быть помечен как вниз. Все IPS, которые должны были направляться на сервер вниз, затем направлены на альтернативный.
Приведенная ниже конфигурация приведена:
```
upstream backend {
  ip_hash;
  server   backend1.example.com;
  server   backend2.example.com;
  server   backend3.example.com  down;
 }
```

### Макс терпит неудачу
В соответствии с настройками круглой робин по умолчанию, балансировщик нагрузки приложения NGINX будет продолжать отправлять данные на виртуальные частные серверы, даже если серверы не отвечают. MAX FAILS может автоматически предотвратить это, предоставляя не реагирующие на серверы неработающие в течение определенного количества времени.
Существует два фактора, связанных с максимальным сбоем: Max \ _fails и Fall \ _timeout. Сбой MAX относится к максимальному количеству неудачных попыток подключиться к серверу, который должен произойти до того, как он будет считаться неактивным. FALL_TIMEOUT указывает длину того, что сервер считается неработающим. Как только время истекает, новые попытки добраться до сервера запустится снова. Значение тайм -аута по умолчанию составляет 10 секунд.
Пример конфигурации может выглядеть так:
```
upstream backend  {
  server backend1.example.com max_fails=3  fail_timeout=15s;
  server backend2.example.com weight=2;
  server backend3.example.com weight=4;
}
```

## Заключение: {#conclusion}

В этом учебном пособии по балансировке нагрузки NGINX мы узнали о NGNIX, балансировании нагрузки и о том, как настроить балансировщик нагрузки NGINX для распространения вашего трафика на несколько серверов. Мы также исследовали различные алгоритмы балансировки нагрузки, такие как круглый робин, хэш и Макс. Если вы запускаете приложение с большим объемом, и вам нужно распределить нагрузку на разных серверах, то Nginx является одним из лучших вариантов для вас. И самое главное, это 100% бесплатный и веб-сервер с открытым исходным кодом.
_ YYOUR может присоединиться к нам на [Twitter][7], [LinkedIn][8] и нашей странице [Facebook][9]. Какой другой мощный балансировщик нагрузки для улучшения доступности и эффективности ресурсов серверов __do вы используете? Полем Если у вас есть какие -либо вопросы или отзывы, пожалуйста, свяжитесь с нами][10].

## Исследовать
Вы можете найти более связанные ниже статьи
  * [Как обеспечить и шифровать Nginx с помощью Let's Encrypt на Ubuntu 20.04][11]
  * [Apache vs Nginx - подробное сравнение в 2021 году][12]



[1]: #webserver
[2]: #loadbalancer
[3]: #setup
[4]: #upstream
[5]: #conclusion
[6]: https://products.containerize.com/solution-stack/nginx
[7]: https://twitter.com/containerize_co
[8]: https://www.linkedin.com/company/containerize/
[9]: http://facebook.com/containerize
[10]: mailto:yasir.saeed@aspose.com
[11]: https://blog.containerize.com/web-server-solution-stack/how-to-secure-nginx-with-letsencrypt-on-ubuntu-20-04/
[12]: https://blog.containerize.com/2021/02/26/apache-vs-nginx-detailed-comparison-in-2021/
